{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL2niGnHv7rA"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SesxXpMhv7rF"
      },
      "source": [
        "# Fundamentals of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCCFf-Grv7rG"
      },
      "source": [
        "## Generalization: The goal of machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Avh5Litv7rG"
      },
      "source": [
        "### Underfitting and overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NrZGw33v7rH"
      },
      "source": [
        "#### Noisy training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wQeWXimv7rH"
      },
      "source": [
        "#### Ambiguous features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN4dbkd9v7rI"
      },
      "source": [
        "#### Rare features and spurious correlations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS4MJupLv7rJ"
      },
      "source": [
        "**Adding white-noise channels or all-zeros channels to MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7-QGk7Bov7rK",
        "outputId": "55791603-b378-4c2a-f6da-be451038b34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUE-ZGfEv7rM"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zero channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zKRk5roUv7rN",
        "outputId": "699f32e5-45bb-4e89-e05d-9ea9d5999305",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 6s 6ms/step - loss: 0.6098 - accuracy: 0.8148 - val_loss: 0.2730 - val_accuracy: 0.9156\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.2489 - accuracy: 0.9213 - val_loss: 0.1749 - val_accuracy: 0.9493\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1616 - accuracy: 0.9503 - val_loss: 0.1491 - val_accuracy: 0.9557\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1141 - accuracy: 0.9641 - val_loss: 0.1558 - val_accuracy: 0.9507\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0835 - accuracy: 0.9731 - val_loss: 0.1439 - val_accuracy: 0.9589\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0626 - accuracy: 0.9798 - val_loss: 0.1240 - val_accuracy: 0.9657\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0451 - accuracy: 0.9860 - val_loss: 0.1387 - val_accuracy: 0.9638\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0355 - accuracy: 0.9889 - val_loss: 0.1231 - val_accuracy: 0.9699\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.1610 - val_accuracy: 0.9590\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.1358 - val_accuracy: 0.9683\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 3s 6ms/step - loss: 0.2863 - accuracy: 0.9171 - val_loss: 0.1496 - val_accuracy: 0.9585\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1177 - accuracy: 0.9653 - val_loss: 0.1115 - val_accuracy: 0.9678\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0778 - accuracy: 0.9770 - val_loss: 0.0922 - val_accuracy: 0.9737\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0559 - accuracy: 0.9837 - val_loss: 0.0774 - val_accuracy: 0.9769\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0419 - accuracy: 0.9877 - val_loss: 0.0826 - val_accuracy: 0.9757\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.0840 - val_accuracy: 0.9769\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 0.0819 - val_accuracy: 0.9768\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.0791 - val_accuracy: 0.9793\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0878 - val_accuracy: 0.9790\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.0953 - val_accuracy: 0.9765\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "history_noise = model.fit(\n",
        "    train_images_with_noise_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model()\n",
        "history_zeros = model.fit(\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m89lBS2v7rN"
      },
      "source": [
        "**Plotting a validation accuracy comparison**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eI8B4i8iv7rO",
        "outputId": "2d33faa2-eeed-4f56-efdc-53b7e2aba59e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9cc11d24d0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, val_acc_noise, \"b-\",\n",
        "         label=\"Validation accuracy with noise channels\")\n",
        "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
        "         label=\"Validation accuracy with zeros channels\")\n",
        "plt.title(\"Effect of noise channels on validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXXaXxEZv7rO"
      },
      "source": [
        "### The nature of generalization in deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZejNYwjmv7rP"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j9uJGh8Lv7rP",
        "outputId": "391a5668-f0b0-4d8a-92c2-f876b922aa83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3166 - accuracy: 0.1031 - val_loss: 2.3105 - val_accuracy: 0.1061\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2993 - accuracy: 0.1177 - val_loss: 2.3140 - val_accuracy: 0.1049\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2903 - accuracy: 0.1278 - val_loss: 2.3206 - val_accuracy: 0.1014\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2761 - accuracy: 0.1392 - val_loss: 2.3322 - val_accuracy: 0.1034\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.2574 - accuracy: 0.1531 - val_loss: 2.3508 - val_accuracy: 0.1006\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 2.2360 - accuracy: 0.1676 - val_loss: 2.3655 - val_accuracy: 0.1002\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 3s 8ms/step - loss: 2.2104 - accuracy: 0.1833 - val_loss: 2.3726 - val_accuracy: 0.0980\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.1823 - accuracy: 0.1983 - val_loss: 2.3919 - val_accuracy: 0.0983\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 2.1522 - accuracy: 0.2174 - val_loss: 2.4109 - val_accuracy: 0.1012\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 2.1195 - accuracy: 0.2343 - val_loss: 2.4375 - val_accuracy: 0.0983\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0867 - accuracy: 0.2492 - val_loss: 2.4618 - val_accuracy: 0.0988\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0524 - accuracy: 0.2662 - val_loss: 2.4904 - val_accuracy: 0.1012\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.0183 - accuracy: 0.2795 - val_loss: 2.5102 - val_accuracy: 0.0983\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9841 - accuracy: 0.2945 - val_loss: 2.5426 - val_accuracy: 0.1022\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9494 - accuracy: 0.3099 - val_loss: 2.5843 - val_accuracy: 0.1026\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.9138 - accuracy: 0.3240 - val_loss: 2.6074 - val_accuracy: 0.1018\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8790 - accuracy: 0.3377 - val_loss: 2.6351 - val_accuracy: 0.1015\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8451 - accuracy: 0.3534 - val_loss: 2.6696 - val_accuracy: 0.1001\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.8119 - accuracy: 0.3670 - val_loss: 2.7168 - val_accuracy: 0.0996\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7791 - accuracy: 0.3778 - val_loss: 2.7570 - val_accuracy: 0.1004\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7465 - accuracy: 0.3939 - val_loss: 2.7925 - val_accuracy: 0.1014\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.7157 - accuracy: 0.4046 - val_loss: 2.8256 - val_accuracy: 0.1019\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6834 - accuracy: 0.4158 - val_loss: 2.8682 - val_accuracy: 0.0986\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6536 - accuracy: 0.4290 - val_loss: 2.9199 - val_accuracy: 0.1017\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.6240 - accuracy: 0.4399 - val_loss: 2.9712 - val_accuracy: 0.0988\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5948 - accuracy: 0.4492 - val_loss: 2.9708 - val_accuracy: 0.0986\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.5664 - accuracy: 0.4600 - val_loss: 3.0410 - val_accuracy: 0.1011\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5398 - accuracy: 0.4696 - val_loss: 3.0773 - val_accuracy: 0.0997\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.5103 - accuracy: 0.4820 - val_loss: 3.1418 - val_accuracy: 0.0972\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4858 - accuracy: 0.4909 - val_loss: 3.1831 - val_accuracy: 0.1012\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4620 - accuracy: 0.4975 - val_loss: 3.2034 - val_accuracy: 0.0975\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4328 - accuracy: 0.5090 - val_loss: 3.2430 - val_accuracy: 0.0981\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.4093 - accuracy: 0.5179 - val_loss: 3.3048 - val_accuracy: 0.0997\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3859 - accuracy: 0.5277 - val_loss: 3.3464 - val_accuracy: 0.0996\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3619 - accuracy: 0.5366 - val_loss: 3.4136 - val_accuracy: 0.1010\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3405 - accuracy: 0.5416 - val_loss: 3.4413 - val_accuracy: 0.0957\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.3168 - accuracy: 0.5504 - val_loss: 3.4921 - val_accuracy: 0.0984\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2933 - accuracy: 0.5597 - val_loss: 3.5571 - val_accuracy: 0.0956\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2716 - accuracy: 0.5680 - val_loss: 3.6019 - val_accuracy: 0.0972\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.2507 - accuracy: 0.5749 - val_loss: 3.6356 - val_accuracy: 0.0972\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2299 - accuracy: 0.5826 - val_loss: 3.6960 - val_accuracy: 0.0978\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.2103 - accuracy: 0.5923 - val_loss: 3.7565 - val_accuracy: 0.0989\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1891 - accuracy: 0.5950 - val_loss: 3.7920 - val_accuracy: 0.0978\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1689 - accuracy: 0.6068 - val_loss: 3.8608 - val_accuracy: 0.0978\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1507 - accuracy: 0.6125 - val_loss: 3.9301 - val_accuracy: 0.0993\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1301 - accuracy: 0.6199 - val_loss: 3.9818 - val_accuracy: 0.0966\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.1144 - accuracy: 0.6252 - val_loss: 4.0401 - val_accuracy: 0.0953\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0968 - accuracy: 0.6317 - val_loss: 4.0955 - val_accuracy: 0.1003\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0790 - accuracy: 0.6370 - val_loss: 4.1413 - val_accuracy: 0.0972\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1.0615 - accuracy: 0.6451 - val_loss: 4.1808 - val_accuracy: 0.0980\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 2s 6ms/step - loss: 1.0452 - accuracy: 0.6474 - val_loss: 4.2390 - val_accuracy: 0.1018\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0281 - accuracy: 0.6546 - val_loss: 4.2874 - val_accuracy: 0.0995\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 1.0107 - accuracy: 0.6640 - val_loss: 4.3372 - val_accuracy: 0.0975\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9940 - accuracy: 0.6661 - val_loss: 4.4170 - val_accuracy: 0.1003\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9820 - accuracy: 0.6710 - val_loss: 4.4850 - val_accuracy: 0.0966\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9626 - accuracy: 0.6771 - val_loss: 4.5266 - val_accuracy: 0.0955\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9492 - accuracy: 0.6840 - val_loss: 4.5843 - val_accuracy: 0.0974\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9360 - accuracy: 0.6890 - val_loss: 4.6235 - val_accuracy: 0.0966\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9206 - accuracy: 0.6945 - val_loss: 4.7133 - val_accuracy: 0.0988\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.9073 - accuracy: 0.6996 - val_loss: 4.7337 - val_accuracy: 0.0996\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8910 - accuracy: 0.7044 - val_loss: 4.7917 - val_accuracy: 0.0989\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.8773 - accuracy: 0.7101 - val_loss: 4.9195 - val_accuracy: 0.0985\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8646 - accuracy: 0.7121 - val_loss: 4.9347 - val_accuracy: 0.0993\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8529 - accuracy: 0.7173 - val_loss: 5.0110 - val_accuracy: 0.1024\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8399 - accuracy: 0.7193 - val_loss: 5.0262 - val_accuracy: 0.1002\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8262 - accuracy: 0.7278 - val_loss: 5.1320 - val_accuracy: 0.1005\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8141 - accuracy: 0.7289 - val_loss: 5.1729 - val_accuracy: 0.0992\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.8030 - accuracy: 0.7345 - val_loss: 5.2549 - val_accuracy: 0.0967\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7883 - accuracy: 0.7401 - val_loss: 5.3353 - val_accuracy: 0.0994\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7784 - accuracy: 0.7445 - val_loss: 5.3995 - val_accuracy: 0.0960\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7643 - accuracy: 0.7494 - val_loss: 5.4380 - val_accuracy: 0.0996\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7529 - accuracy: 0.7520 - val_loss: 5.4877 - val_accuracy: 0.1004\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7435 - accuracy: 0.7555 - val_loss: 5.5464 - val_accuracy: 0.1002\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7316 - accuracy: 0.7609 - val_loss: 5.5987 - val_accuracy: 0.0980\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.7209 - accuracy: 0.7644 - val_loss: 5.6924 - val_accuracy: 0.0974\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.7105 - accuracy: 0.7665 - val_loss: 5.7725 - val_accuracy: 0.0962\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6982 - accuracy: 0.7705 - val_loss: 5.8432 - val_accuracy: 0.0998\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6877 - accuracy: 0.7762 - val_loss: 5.8914 - val_accuracy: 0.1039\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6806 - accuracy: 0.7778 - val_loss: 5.9632 - val_accuracy: 0.0992\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6694 - accuracy: 0.7811 - val_loss: 6.0290 - val_accuracy: 0.0975\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6585 - accuracy: 0.7859 - val_loss: 6.0517 - val_accuracy: 0.1008\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6471 - accuracy: 0.7870 - val_loss: 6.1244 - val_accuracy: 0.0997\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6381 - accuracy: 0.7947 - val_loss: 6.2058 - val_accuracy: 0.1010\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6316 - accuracy: 0.7928 - val_loss: 6.2597 - val_accuracy: 0.0978\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6206 - accuracy: 0.7988 - val_loss: 6.3546 - val_accuracy: 0.0993\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.6128 - accuracy: 0.8021 - val_loss: 6.3782 - val_accuracy: 0.1008\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6036 - accuracy: 0.8037 - val_loss: 6.4935 - val_accuracy: 0.0970\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5941 - accuracy: 0.8073 - val_loss: 6.4980 - val_accuracy: 0.1002\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5861 - accuracy: 0.8112 - val_loss: 6.6273 - val_accuracy: 0.0962\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5764 - accuracy: 0.8137 - val_loss: 6.6807 - val_accuracy: 0.0969\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5713 - accuracy: 0.8151 - val_loss: 6.7183 - val_accuracy: 0.0999\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5592 - accuracy: 0.8199 - val_loss: 6.7947 - val_accuracy: 0.1005\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5513 - accuracy: 0.8214 - val_loss: 6.8935 - val_accuracy: 0.0988\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5446 - accuracy: 0.8229 - val_loss: 6.9344 - val_accuracy: 0.0968\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5365 - accuracy: 0.8277 - val_loss: 7.0241 - val_accuracy: 0.0983\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5300 - accuracy: 0.8285 - val_loss: 7.1280 - val_accuracy: 0.0972\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5223 - accuracy: 0.8320 - val_loss: 7.1294 - val_accuracy: 0.0969\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.5152 - accuracy: 0.8345 - val_loss: 7.1825 - val_accuracy: 0.0982\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.5071 - accuracy: 0.8369 - val_loss: 7.2666 - val_accuracy: 0.1023\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.4994 - accuracy: 0.8396 - val_loss: 7.3903 - val_accuracy: 0.0986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9d3012d890>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "random_train_labels = train_labels[:]\n",
        "np.random.shuffle(random_train_labels)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, random_train_labels,\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeaGXjrWv7rQ"
      },
      "source": [
        "#### The manifold hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrJwYadBv7rQ"
      },
      "source": [
        "#### Interpolation as a source of generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L-KctCcv7rQ"
      },
      "source": [
        "#### Why deep learning works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SVdUjJ9v7rR"
      },
      "source": [
        "#### Training data is paramount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kiHgn-yv7rR"
      },
      "source": [
        "## Evaluating machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3k58ribv7rR"
      },
      "source": [
        "### Training, validation, and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QK9d2qYv7rS"
      },
      "source": [
        "#### Simple hold-out validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deN-cpy6v7rT"
      },
      "source": [
        "#### K-fold validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyFQf3njv7rT"
      },
      "source": [
        "#### Iterated K-fold validation with shuffling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdzUqXr2v7rT"
      },
      "source": [
        "### Beating a common-sense baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLt7kyWQv7rU"
      },
      "source": [
        "### Things to keep in mind about model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtnoaaQPv7rU"
      },
      "source": [
        "## Improving model fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL3UhhkZv7rU"
      },
      "source": [
        "### Tuning key gradient descent parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h6NQ-fSv7rU"
      },
      "source": [
        "**Training a MNIST model with an incorrectly high learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-9koLssNv7rU",
        "outputId": "121aeda5-261f-4cb3-b342-acf3b142a199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 1019.6594 - accuracy: 0.4232 - val_loss: 2.2699 - val_accuracy: 0.2481\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 3.5522 - accuracy: 0.2881 - val_loss: 3.5557 - val_accuracy: 0.3697\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 3.7754 - accuracy: 0.2878 - val_loss: 2.1309 - val_accuracy: 0.2444\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.7557 - accuracy: 0.2660 - val_loss: 2.1806 - val_accuracy: 0.2587\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.6439 - accuracy: 0.2586 - val_loss: 2.5043 - val_accuracy: 0.2502\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.7448 - accuracy: 0.2515 - val_loss: 2.1100 - val_accuracy: 0.2222\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.5356 - accuracy: 0.2520 - val_loss: 4.0546 - val_accuracy: 0.2787\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.4493 - accuracy: 0.2496 - val_loss: 2.0049 - val_accuracy: 0.2482\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 2.7661 - accuracy: 0.2640 - val_loss: 2.9548 - val_accuracy: 0.2615\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 2.3204 - accuracy: 0.2707 - val_loss: 2.1276 - val_accuracy: 0.3052\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cc0b45d90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuOCAP_pv7rV"
      },
      "source": [
        "**The same model with a more appropriate learning rate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zhK35X4Dv7rV",
        "outputId": "f9bc5b14-8c07-409b-cbf9-b50117178677",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.4057 - accuracy: 0.9100 - val_loss: 0.2097 - val_accuracy: 0.9456\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.1441 - accuracy: 0.9629 - val_loss: 0.1525 - val_accuracy: 0.9614\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1187 - accuracy: 0.9724 - val_loss: 0.1457 - val_accuracy: 0.9718\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0960 - accuracy: 0.9780 - val_loss: 0.1931 - val_accuracy: 0.9682\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0850 - accuracy: 0.9817 - val_loss: 0.2075 - val_accuracy: 0.9716\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0806 - accuracy: 0.9833 - val_loss: 0.2893 - val_accuracy: 0.9599\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0687 - accuracy: 0.9858 - val_loss: 0.2357 - val_accuracy: 0.9722\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0659 - accuracy: 0.9873 - val_loss: 0.2189 - val_accuracy: 0.9756\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.0512 - accuracy: 0.9894 - val_loss: 0.2779 - val_accuracy: 0.9737\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0555 - accuracy: 0.9903 - val_loss: 0.2885 - val_accuracy: 0.9724\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9cbcd71910>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSqdBAnfv7rV"
      },
      "source": [
        "### Leveraging better architecture priors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK58zutFv7rV"
      },
      "source": [
        "### Increasing model capacity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h56lYd9Xv7rW"
      },
      "source": [
        "**A simple logistic regression on MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eewvD0-6v7rW",
        "outputId": "5d6ffe4d-da6e-4d1f-8bbd-151a384a80ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.6728 - accuracy: 0.8340 - val_loss: 0.3571 - val_accuracy: 0.9046\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.9034 - val_loss: 0.3075 - val_accuracy: 0.9150\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.9118 - val_loss: 0.2897 - val_accuracy: 0.9194\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2993 - accuracy: 0.9169 - val_loss: 0.2806 - val_accuracy: 0.9223\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2895 - accuracy: 0.9193 - val_loss: 0.2755 - val_accuracy: 0.9239\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2830 - accuracy: 0.9216 - val_loss: 0.2699 - val_accuracy: 0.9277\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2783 - accuracy: 0.9223 - val_loss: 0.2689 - val_accuracy: 0.9263\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2742 - accuracy: 0.9236 - val_loss: 0.2665 - val_accuracy: 0.9277\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2714 - accuracy: 0.9249 - val_loss: 0.2651 - val_accuracy: 0.9286\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2688 - accuracy: 0.9253 - val_loss: 0.2644 - val_accuracy: 0.9288\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.9263 - val_loss: 0.2628 - val_accuracy: 0.9304\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2647 - accuracy: 0.9267 - val_loss: 0.2624 - val_accuracy: 0.9293\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2632 - accuracy: 0.9279 - val_loss: 0.2630 - val_accuracy: 0.9293\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2617 - accuracy: 0.9278 - val_loss: 0.2617 - val_accuracy: 0.9298\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2604 - accuracy: 0.9283 - val_loss: 0.2604 - val_accuracy: 0.9302\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2593 - accuracy: 0.9287 - val_loss: 0.2611 - val_accuracy: 0.9313\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.2582 - accuracy: 0.9291 - val_loss: 0.2611 - val_accuracy: 0.9296\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2572 - accuracy: 0.9298 - val_loss: 0.2612 - val_accuracy: 0.9304\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2565 - accuracy: 0.9297 - val_loss: 0.2613 - val_accuracy: 0.9308\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.2557 - accuracy: 0.9304 - val_loss: 0.2609 - val_accuracy: 0.9315\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_small_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dNrw4_rWv7rW",
        "outputId": "a7d15e9f-315f-46d2-fe1e-28a11107d951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f9cbcba9750>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_loss = history_small_model.history[\"val_loss\"]\n",
        "epochs = range(1, 21)\n",
        "plt.plot(epochs, val_loss, \"b--\",\n",
        "         label=\"Validation loss\")\n",
        "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iNdsdjg5v7rW",
        "outputId": "bf6f4396-6128-43bb-9304-7122195c8637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "375/375 [==============================] - 2s 5ms/step - loss: 0.3618 - accuracy: 0.8998 - val_loss: 0.1888 - val_accuracy: 0.9449\n",
            "Epoch 2/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1602 - accuracy: 0.9536 - val_loss: 0.1399 - val_accuracy: 0.9587\n",
            "Epoch 3/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.1139 - accuracy: 0.9659 - val_loss: 0.1152 - val_accuracy: 0.9643\n",
            "Epoch 4/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0889 - accuracy: 0.9730 - val_loss: 0.1155 - val_accuracy: 0.9663\n",
            "Epoch 5/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0718 - accuracy: 0.9780 - val_loss: 0.0958 - val_accuracy: 0.9711\n",
            "Epoch 6/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0579 - accuracy: 0.9819 - val_loss: 0.0947 - val_accuracy: 0.9726\n",
            "Epoch 7/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0476 - accuracy: 0.9850 - val_loss: 0.0877 - val_accuracy: 0.9751\n",
            "Epoch 8/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 0.1010 - val_accuracy: 0.9717\n",
            "Epoch 9/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0969 - val_accuracy: 0.9744\n",
            "Epoch 10/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0993 - val_accuracy: 0.9746\n",
            "Epoch 11/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.1056 - val_accuracy: 0.9727\n",
            "Epoch 12/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.9937 - val_loss: 0.1176 - val_accuracy: 0.9718\n",
            "Epoch 13/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.1155 - val_accuracy: 0.9733\n",
            "Epoch 14/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.1099 - val_accuracy: 0.9760\n",
            "Epoch 15/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.1156 - val_accuracy: 0.9749\n",
            "Epoch 16/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1195 - val_accuracy: 0.9761\n",
            "Epoch 17/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1265 - val_accuracy: 0.9742\n",
            "Epoch 18/20\n",
            "375/375 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.1415 - val_accuracy: 0.9722\n",
            "Epoch 19/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.1316 - val_accuracy: 0.9779\n",
            "Epoch 20/20\n",
            "375/375 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1359 - val_accuracy: 0.9751\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_large_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDx07tH1v7rX"
      },
      "source": [
        "## Improving generalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toG2Oe1Dv7rX"
      },
      "source": [
        "### Dataset curation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odDbVt0wv7rX"
      },
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdna-8aGv7rX"
      },
      "source": [
        "### Using early stopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsB05RCpv7rX"
      },
      "source": [
        "### Regularizing your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgET_4eYv7rY"
      },
      "source": [
        "#### Reducing the network's size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nXLAgxFv7rY"
      },
      "source": [
        "**Original model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vE55tVxmv7rY",
        "outputId": "39c16ef9-4a47-45a9-ca5e-360ef8b8be34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Epoch 1/20\n",
            "30/30 [==============================] - 3s 45ms/step - loss: 0.5497 - accuracy: 0.7751 - val_loss: 0.4246 - val_accuracy: 0.8583\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3382 - accuracy: 0.8973 - val_loss: 0.3292 - val_accuracy: 0.8778\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2389 - accuracy: 0.9265 - val_loss: 0.2913 - val_accuracy: 0.8857\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1871 - accuracy: 0.9407 - val_loss: 0.2839 - val_accuracy: 0.8861\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1495 - accuracy: 0.9531 - val_loss: 0.2788 - val_accuracy: 0.8885\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.1233 - accuracy: 0.9623 - val_loss: 0.2951 - val_accuracy: 0.8859\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1016 - accuracy: 0.9695 - val_loss: 0.3183 - val_accuracy: 0.8816\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0819 - accuracy: 0.9778 - val_loss: 0.3253 - val_accuracy: 0.8831\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.3607 - val_accuracy: 0.8774\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0555 - accuracy: 0.9858 - val_loss: 0.3739 - val_accuracy: 0.8795\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0447 - accuracy: 0.9903 - val_loss: 0.4183 - val_accuracy: 0.8749\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0364 - accuracy: 0.9919 - val_loss: 0.4357 - val_accuracy: 0.8747\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0288 - accuracy: 0.9947 - val_loss: 0.4645 - val_accuracy: 0.8743\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0221 - accuracy: 0.9965 - val_loss: 0.4895 - val_accuracy: 0.8748\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: 0.5250 - val_accuracy: 0.8718\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0128 - accuracy: 0.9978 - val_loss: 0.6608 - val_accuracy: 0.8573\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.5918 - val_accuracy: 0.8679\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0086 - accuracy: 0.9989 - val_loss: 0.6261 - val_accuracy: 0.8677\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.6868 - val_accuracy: 0.8678\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.7219 - val_accuracy: 0.8686\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "train_data = vectorize_sequences(train_data)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_original = model.fit(train_data, train_labels,\n",
        "                             epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFovrysEv7rY"
      },
      "source": [
        "**Version of the model with lower capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eTHkQnX4v7rY",
        "outputId": "074c77f8-fcf4-4112-ebb6-e55fd1b88be7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 36ms/step - loss: 0.5552 - accuracy: 0.7779 - val_loss: 0.4584 - val_accuracy: 0.8450\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3837 - accuracy: 0.8922 - val_loss: 0.3661 - val_accuracy: 0.8808\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3006 - accuracy: 0.9141 - val_loss: 0.3235 - val_accuracy: 0.8840\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2487 - accuracy: 0.9272 - val_loss: 0.2957 - val_accuracy: 0.8905\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2111 - accuracy: 0.9391 - val_loss: 0.2829 - val_accuracy: 0.8914\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.1832 - accuracy: 0.9476 - val_loss: 0.2758 - val_accuracy: 0.8913\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1616 - accuracy: 0.9527 - val_loss: 0.2741 - val_accuracy: 0.8920\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.1435 - accuracy: 0.9589 - val_loss: 0.2753 - val_accuracy: 0.8909\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1278 - accuracy: 0.9633 - val_loss: 0.2797 - val_accuracy: 0.8894\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1143 - accuracy: 0.9685 - val_loss: 0.2873 - val_accuracy: 0.8870\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1029 - accuracy: 0.9738 - val_loss: 0.2947 - val_accuracy: 0.8858\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0921 - accuracy: 0.9761 - val_loss: 0.3078 - val_accuracy: 0.8829\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0836 - accuracy: 0.9791 - val_loss: 0.3229 - val_accuracy: 0.8802\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0752 - accuracy: 0.9825 - val_loss: 0.3267 - val_accuracy: 0.8832\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0674 - accuracy: 0.9845 - val_loss: 0.3443 - val_accuracy: 0.8786\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0612 - accuracy: 0.9862 - val_loss: 0.3551 - val_accuracy: 0.8789\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0542 - accuracy: 0.9885 - val_loss: 0.3768 - val_accuracy: 0.8758\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0494 - accuracy: 0.9891 - val_loss: 0.3870 - val_accuracy: 0.8766\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0436 - accuracy: 0.9913 - val_loss: 0.4011 - val_accuracy: 0.8767\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.0390 - accuracy: 0.9921 - val_loss: 0.4378 - val_accuracy: 0.8702\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_smaller_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXK51JQ7v7rZ"
      },
      "source": [
        "**Version of the model with higher capacity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3LD3CIgKv7ra",
        "outputId": "a9c90a9f-1681-4c21-8faf-1302babec890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 48ms/step - loss: 0.5533 - accuracy: 0.7453 - val_loss: 0.3009 - val_accuracy: 0.8808\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.2644 - accuracy: 0.8972 - val_loss: 0.3961 - val_accuracy: 0.8374\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1638 - accuracy: 0.9377 - val_loss: 0.2739 - val_accuracy: 0.8910\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0895 - accuracy: 0.9707 - val_loss: 0.3896 - val_accuracy: 0.8802\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.1295 - accuracy: 0.9779 - val_loss: 0.3566 - val_accuracy: 0.8741\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 0.4713 - val_accuracy: 0.8825\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 8.6927e-04 - accuracy: 1.0000 - val_loss: 0.6043 - val_accuracy: 0.8852\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 1.2475e-04 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.8845\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 2.3240e-05 - accuracy: 1.0000 - val_loss: 0.8222 - val_accuracy: 0.8835\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 4.6290e-06 - accuracy: 1.0000 - val_loss: 0.9204 - val_accuracy: 0.8833\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 1.2006e-06 - accuracy: 1.0000 - val_loss: 1.0059 - val_accuracy: 0.8833\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 3.7521e-07 - accuracy: 1.0000 - val_loss: 1.0824 - val_accuracy: 0.8832\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 1.3235e-07 - accuracy: 1.0000 - val_loss: 1.1491 - val_accuracy: 0.8836\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 5.8685e-08 - accuracy: 1.0000 - val_loss: 1.1987 - val_accuracy: 0.8829\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 3.1643e-08 - accuracy: 1.0000 - val_loss: 1.2348 - val_accuracy: 0.8829\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 2.0741e-08 - accuracy: 1.0000 - val_loss: 1.2584 - val_accuracy: 0.8830\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 1.5338e-08 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.8828\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 1.2183e-08 - accuracy: 1.0000 - val_loss: 1.2901 - val_accuracy: 0.8834\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 1.0097e-08 - accuracy: 1.0000 - val_loss: 1.3007 - val_accuracy: 0.8831\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 8.6350e-09 - accuracy: 1.0000 - val_loss: 1.3118 - val_accuracy: 0.8829\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_larger_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSWWiMFWv7ra"
      },
      "source": [
        "#### Adding weight regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnR9Vw7kv7ra"
      },
      "source": [
        "**Adding L2 weight regularization to the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O7am6imGv7rb",
        "outputId": "f376b2f6-af28-4fa5-a7f8-e3ee16e4ca63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 36ms/step - loss: 0.5913 - accuracy: 0.7837 - val_loss: 0.4740 - val_accuracy: 0.8447\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3935 - accuracy: 0.8939 - val_loss: 0.3801 - val_accuracy: 0.8879\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3223 - accuracy: 0.9169 - val_loss: 0.3628 - val_accuracy: 0.8859\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2903 - accuracy: 0.9250 - val_loss: 0.3693 - val_accuracy: 0.8782\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2713 - accuracy: 0.9327 - val_loss: 0.3538 - val_accuracy: 0.8865\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2598 - accuracy: 0.9367 - val_loss: 0.3573 - val_accuracy: 0.8852\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2506 - accuracy: 0.9402 - val_loss: 0.3697 - val_accuracy: 0.8816\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2373 - accuracy: 0.9483 - val_loss: 0.3623 - val_accuracy: 0.8833\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2340 - accuracy: 0.9445 - val_loss: 0.3706 - val_accuracy: 0.8820\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2269 - accuracy: 0.9496 - val_loss: 0.3778 - val_accuracy: 0.8803\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2251 - accuracy: 0.9499 - val_loss: 0.3792 - val_accuracy: 0.8795\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2212 - accuracy: 0.9507 - val_loss: 0.3934 - val_accuracy: 0.8763\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2141 - accuracy: 0.9523 - val_loss: 0.3967 - val_accuracy: 0.8753\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2110 - accuracy: 0.9561 - val_loss: 0.4879 - val_accuracy: 0.8491\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.2108 - accuracy: 0.9553 - val_loss: 0.3931 - val_accuracy: 0.8793\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2020 - accuracy: 0.9599 - val_loss: 0.4237 - val_accuracy: 0.8702\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2056 - accuracy: 0.9568 - val_loss: 0.4226 - val_accuracy: 0.8715\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.2001 - accuracy: 0.9594 - val_loss: 0.4046 - val_accuracy: 0.8779\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.1988 - accuracy: 0.9605 - val_loss: 0.4059 - val_accuracy: 0.8763\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.1947 - accuracy: 0.9615 - val_loss: 0.4147 - val_accuracy: 0.8760\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_l2_reg = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k64rAjRGv7rb"
      },
      "source": [
        "**Different weight regularizers available in Keras**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "w5RkkuE5v7rb",
        "outputId": "7799f8f2-d91b-4193-9a60-9e1da086866e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.regularizers.L1L2 at 0x7f9caf9bac50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "regularizers.l1(0.001)\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK_x3-d2v7rc"
      },
      "source": [
        "#### Adding dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRuHGOefv7rc"
      },
      "source": [
        "**Adding dropout to the IMDB model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "76D58mqOv7ri",
        "outputId": "db84d1e2-ce19-4b0e-f353-663032331509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 36ms/step - loss: 0.6353 - accuracy: 0.6287 - val_loss: 0.5232 - val_accuracy: 0.8548\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.5308 - accuracy: 0.7381 - val_loss: 0.4320 - val_accuracy: 0.8736\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.4631 - accuracy: 0.7921 - val_loss: 0.3682 - val_accuracy: 0.8699\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.4037 - accuracy: 0.8289 - val_loss: 0.3282 - val_accuracy: 0.8891\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3528 - accuracy: 0.8669 - val_loss: 0.2933 - val_accuracy: 0.8939\n",
            "Epoch 6/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3103 - accuracy: 0.8859 - val_loss: 0.2802 - val_accuracy: 0.8919\n",
            "Epoch 7/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2764 - accuracy: 0.9031 - val_loss: 0.2718 - val_accuracy: 0.8948\n",
            "Epoch 8/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2522 - accuracy: 0.9121 - val_loss: 0.2903 - val_accuracy: 0.8847\n",
            "Epoch 9/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2243 - accuracy: 0.9274 - val_loss: 0.2798 - val_accuracy: 0.8931\n",
            "Epoch 10/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2100 - accuracy: 0.9325 - val_loss: 0.2917 - val_accuracy: 0.8926\n",
            "Epoch 11/20\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.1804 - accuracy: 0.9387 - val_loss: 0.3074 - val_accuracy: 0.8904\n",
            "Epoch 12/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1612 - accuracy: 0.9464 - val_loss: 0.3391 - val_accuracy: 0.8907\n",
            "Epoch 13/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1498 - accuracy: 0.9500 - val_loss: 0.3541 - val_accuracy: 0.8878\n",
            "Epoch 14/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1368 - accuracy: 0.9556 - val_loss: 0.3662 - val_accuracy: 0.8901\n",
            "Epoch 15/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.1282 - accuracy: 0.9584 - val_loss: 0.3924 - val_accuracy: 0.8890\n",
            "Epoch 16/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.1168 - accuracy: 0.9618 - val_loss: 0.4251 - val_accuracy: 0.8844\n",
            "Epoch 17/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.1078 - accuracy: 0.9651 - val_loss: 0.4340 - val_accuracy: 0.8867\n",
            "Epoch 18/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.1042 - accuracy: 0.9653 - val_loss: 0.4512 - val_accuracy: 0.8834\n",
            "Epoch 19/20\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.0977 - accuracy: 0.9676 - val_loss: 0.4755 - val_accuracy: 0.8868\n",
            "Epoch 20/20\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.0932 - accuracy: 0.9705 - val_loss: 0.5109 - val_accuracy: 0.8861\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_dropout = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcXv2gADv7ri"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chapter05_fundamentals-of-ml.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}